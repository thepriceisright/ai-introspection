{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9eb5750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: project .venv directory not found. Create it via `python -m venv .venv`.\n",
      "Loaded variables from .env (existing environment values are preserved).\n",
      "Anthropic: set\n",
      "OpenAI   : set\n",
      "OpenRouter: set\n",
      "HuggingFace: set (HUGGINGFACEHUB_API_TOKEN)\n"
     ]
    }
   ],
   "source": [
    "#@title Load environment variables from the .env file\n",
    "from pathlib import Path\n",
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "def _load_package():\n",
    "    try:\n",
    "        return importlib.import_module(\"introspect_repro\")\n",
    "    except ModuleNotFoundError:\n",
    "        search_roots = [Path.cwd().resolve()]\n",
    "        search_roots += list(search_roots[0].parents)\n",
    "        for root in search_roots:\n",
    "            src_dir = root / \"src\"\n",
    "            if not src_dir.is_dir():\n",
    "                continue\n",
    "            if str(src_dir) not in sys.path:\n",
    "                sys.path.append(str(src_dir))\n",
    "            try:\n",
    "                return importlib.import_module(\"introspect_repro\")\n",
    "            except ModuleNotFoundError:\n",
    "                continue\n",
    "        raise\n",
    "\n",
    "\n",
    "pkg = _load_package()\n",
    "if not hasattr(pkg, \"activate_local_venv\"):\n",
    "    pkg = importlib.reload(pkg)\n",
    "\n",
    "activate_local_venv = getattr(pkg, \"activate_local_venv\")\n",
    "load_project_env = getattr(pkg, \"load_project_env\")\n",
    "get_hf_token = getattr(pkg, \"get_hf_token\", lambda: None)\n",
    "hf_token_env_keys = getattr(pkg, \"HF_TOKEN_ENV_KEYS\", (\n",
    "    \"HUGGINGFACEHUB_API_TOKEN\",\n",
    "    \"HUGGINGFACE_TOKEN\",\n",
    "    \"HF_TOKEN\",\n",
    "    \"HF_API_TOKEN\",\n",
    "))\n",
    "\n",
    "activate_local_venv()\n",
    "load_project_env()\n",
    "\n",
    "project_root = Path(pkg.__file__).resolve().parent.parent\n",
    "project_venv = project_root / \".venv\"\n",
    "interpreter_path = Path(sys.executable)\n",
    "if project_venv.exists():\n",
    "    if project_venv in interpreter_path.parents:\n",
    "        print(f\"Using interpreter: {interpreter_path}\")\n",
    "    else:\n",
    "        print(f\"Warning: kernel interpreter {interpreter_path} is outside .venv; added .venv site-packages to sys.path.\")\n",
    "else:\n",
    "    print(\"Warning: project .venv directory not found. Create it via `python -m venv .venv`.\")\n",
    "\n",
    "print(\"Loaded variables from .env (existing environment values are preserved).\")\n",
    "status_labels = (\n",
    "    (\"ANTHROPIC_API_KEY\", \"Anthropic\"),\n",
    "    (\"OPENAI_API_KEY\", \"OpenAI   \"),\n",
    "    (\"OPENROUTER_API_KEY\", \"OpenRouter\"),\n",
    ")\n",
    "for key, label in status_labels:\n",
    "    print(f\"{label}: {'set' if os.environ.get(key) else 'not set'}\")\n",
    "\n",
    "hf_token = get_hf_token()\n",
    "if hf_token:\n",
    "    first_key = next((key for key in hf_token_env_keys if os.environ.get(key)), None)\n",
    "    if first_key:\n",
    "        print(f\"HuggingFace: set ({first_key})\")\n",
    "    else:\n",
    "        print(\"HuggingFace: set\")\n",
    "else:\n",
    "    print(\"HuggingFace: not set\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e332c472",
   "metadata": {},
   "source": [
    "# Publication‑Style Panels for *Introspective Awareness* Repro\n",
    "\n",
    "This notebook assembles **multi‑panel figures** that mirror the layouts used in the paper.  \n",
    "It assumes you have already run the experiment scripts and have results in `runs/<timestamp>/...`.\n",
    "\n",
    "> Design: each small chart is rendered as a single stand‑alone figure and then **tiled** into a grid using Pillow (no matplotlib subplots).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b4e7a4",
   "metadata": {},
   "source": [
    "## 0) Environment setup\n",
    "Make sure the repro harness is available in `./src`. If you used the main notebook, you already have it. Otherwise unzip/place it here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b1415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for src\n",
    "import os\n",
    "print(\"Have ./src? ->\", os.path.isdir(\"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26108a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /opt/jhvenv/lib/python3.12/site-packages (11.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install small helper for image tiling\n",
    "%pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6dbd3",
   "metadata": {},
   "source": [
    "## 1) Helpers\n",
    "Utilities to tile images into a grid and to locate your latest run directories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "587792bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helpers ready\n"
     ]
    }
   ],
   "source": [
    "# Panel helpers: tiling and metrics\n",
    "import os, math, glob, json\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.introspect_repro.plotting.utils import load_results\n",
    "from src.introspect_repro.plotting.plot_injected_thoughts import compute_metrics\n",
    "\n",
    "def tile_images(image_paths, out_path, n_cols=2, pad=10, bg=\"white\"):\n",
    "    imgs = [Image.open(p).convert(\"RGB\") for p in image_paths]\n",
    "    if not imgs:\n",
    "        raise ValueError(\"No images to tile\")\n",
    "    w = max(i.width for i in imgs)\n",
    "    h = max(i.height for i in imgs)\n",
    "    n_rows = math.ceil(len(imgs) / n_cols)\n",
    "    canvas = Image.new(\"RGB\", (n_cols*w + (n_cols+1)*pad, n_rows*h + (n_rows+1)*pad), bg)\n",
    "    for idx, im in enumerate(imgs):\n",
    "        r = idx // n_cols; c = idx % n_cols\n",
    "        x = pad + c*(w+pad); y = pad + r*(h+pad)\n",
    "        offx = x + (w - im.width)//2\n",
    "        offy = y + (h - im.height)//2\n",
    "        canvas.paste(im, (offx, offy))\n",
    "    canvas.save(out_path)\n",
    "    return out_path\n",
    "\n",
    "def latest_run_dir(name):\n",
    "    cands = glob.glob(os.path.join(\"runs\", \"*\", name))\n",
    "    return max(cands, key=os.path.getmtime) if cands else None\n",
    "\n",
    "print(\"helpers ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8cb4f2",
   "metadata": {},
   "source": [
    "## 2) Injected Thoughts — multi‑strength layer‑wise panel\n",
    "For each **strength**, render a line chart (awareness / affirmative / mentions / false positives), then tile them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ce9673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> /opt/jhvenv/bin/python -m src.introspect_repro.plotting.plot_injected_thoughts --run-dir runs/20251103_092215/injected_thoughts --strength 1 --save runs/20251103_092215/injected_thoughts/layerwise_strength1.png\n",
      ">>> /opt/jhvenv/bin/python -m src.introspect_repro.plotting.plot_injected_thoughts --run-dir runs/20251103_092215/injected_thoughts --strength 2 --save runs/20251103_092215/injected_thoughts/layerwise_strength2.png\n",
      ">>> /opt/jhvenv/bin/python -m src.introspect_repro.plotting.plot_injected_thoughts --run-dir runs/20251103_092215/injected_thoughts --strength 4 --save runs/20251103_092215/injected_thoughts/layerwise_strength4.png\n",
      ">>> /opt/jhvenv/bin/python -m src.introspect_repro.plotting.plot_injected_thoughts --run-dir runs/20251103_092215/injected_thoughts --strength 8 --save runs/20251103_092215/injected_thoughts/layerwise_strength8.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs/20251103_092215/injected_thoughts/panel_injected_thoughts.png'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Injected‑Thoughts panel\n",
    "RUN_DIR = latest_run_dir(\"injected_thoughts\")  #@param {type:\"string\"}\n",
    "STRENGTHS = [1,2,4,8]                           #@param\n",
    "N_COLS = 2                                       #@param {type:\"integer\"}\n",
    "OUT_PATH = os.path.join(RUN_DIR, \"panel_injected_thoughts.png\")  #@param {type:\"string\"}\n",
    "\n",
    "per_strength_paths = []\n",
    "import sys, subprocess\n",
    "for s in STRENGTHS:\n",
    "    out_png = os.path.join(RUN_DIR, f\"layerwise_strength{s}.png\")\n",
    "    cmd = [sys.executable, \"-m\", \"src.introspect_repro.plotting.plot_injected_thoughts\",\n",
    "           \"--run-dir\", RUN_DIR, \"--strength\", str(s), \"--save\", out_png]\n",
    "    print(\">>>\", \" \".join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "    per_strength_paths.append(out_png)\n",
    "\n",
    "panel_path = tile_images(per_strength_paths, OUT_PATH, n_cols=N_COLS)\n",
    "panel_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a0dd04",
   "metadata": {},
   "source": [
    "## 3) Thought vs Text — multi‑strength layer‑wise panel\n",
    "One chart per **strength** (identify‑thought vs exact‑repeat), tiled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52c04bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> /opt/jhvenv/bin/python -m src.introspect_repro.plotting.plot_thought_vs_text --run-dir runs/20251103_120524/thought_vs_text --strength 1 --save runs/20251103_120524/thought_vs_text/tvt_layerwise_strength1.png\n",
      ">>> /opt/jhvenv/bin/python -m src.introspect_repro.plotting.plot_thought_vs_text --run-dir runs/20251103_120524/thought_vs_text --strength 2 --save runs/20251103_120524/thought_vs_text/tvt_layerwise_strength2.png\n",
      ">>> /opt/jhvenv/bin/python -m src.introspect_repro.plotting.plot_thought_vs_text --run-dir runs/20251103_120524/thought_vs_text --strength 4 --save runs/20251103_120524/thought_vs_text/tvt_layerwise_strength4.png\n",
      ">>> /opt/jhvenv/bin/python -m src.introspect_repro.plotting.plot_thought_vs_text --run-dir runs/20251103_120524/thought_vs_text --strength 8 --save runs/20251103_120524/thought_vs_text/tvt_layerwise_strength8.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs/20251103_120524/thought_vs_text/panel_thought_vs_text.png'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Thought‑vs‑Text panel\n",
    "RUN_DIR = latest_run_dir(\"thought_vs_text\")   #@param {type:\"string\"}\n",
    "STRENGTHS = [1,2,4,8]                          #@param\n",
    "N_COLS = 2                                     #@param {type:\"integer\"}\n",
    "OUT_PATH = os.path.join(RUN_DIR, \"panel_thought_vs_text.png\")  #@param {type:\"string\"}\n",
    "\n",
    "per_strength_paths = []\n",
    "import sys, subprocess\n",
    "for s in STRENGTHS:\n",
    "    out_png = os.path.join(RUN_DIR, f\"tvt_layerwise_strength{s}.png\")\n",
    "    cmd = [sys.executable, \"-m\", \"src.introspect_repro.plotting.plot_thought_vs_text\",\n",
    "           \"--run-dir\", RUN_DIR, \"--strength\", str(s), \"--save\", out_png]\n",
    "    print(\">>>\", \" \".join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "    per_strength_paths.append(out_png)\n",
    "\n",
    "panel_path = tile_images(per_strength_paths, OUT_PATH, n_cols=N_COLS)\n",
    "panel_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f581b0",
   "metadata": {},
   "source": [
    "## 4) Prefill Intention — three‑condition panel (control / matched / random‑other)\n",
    "\n",
    "You’ll need three sibling directories under the same `runs/<timestamp>/` root:\n",
    "- `prefill_control` (run prefill with `--strength 0`),  \n",
    "- `prefill_intention` (matched concept injection),  \n",
    "- `prefill_random` (random other word; generated by helper below).\n",
    "\n",
    "Each cell below renders a chart per **condition × strength** and tiles into a grid like the panel on *page 24* of the paper. fileciteturn0file0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "963aaa28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f4a31021b04f5091b9a201f16f5abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "282555e854f341e2abd717c2269e02e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8179941962459bb59c917eb1414811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3a3cb1a59b04345bd858ed3d5c95af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a96640bc5fa442f9160bd41323dcc43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a0b923a57543cabe23119ea59a4896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fea73f8d6444c30aa2a1a11e45f22f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70cd87ffbbb4b4db031ebc210a95e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d4545033bda48758c391cba4e5d9ab4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdba038d88b4b8e9fd5aad9ad7d5523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602e0c38616d48b99adee1bc1619b650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76d10443a224150b75cc0a83077b9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 31.35 GiB of which 1.86 GiB is free. Process 3433 has 602.00 MiB memory in use. Including non-PyTorch memory, this process has 28.68 GiB memory in use. Of the allocated memory 28.08 GiB is allocated by PyTorch, and 19.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOutOfMemoryError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     25\u001b[39m model, tok = load_model_and_tokenizer(HF_MODEL, device=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m                                       load_in_4bit=\u001b[38;5;28mglobals\u001b[39m().get(\u001b[33m\"\u001b[39m\u001b[33mLOAD_IN_4BIT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m     27\u001b[39m                                       load_in_8bit=\u001b[38;5;28mglobals\u001b[39m().get(\u001b[33m\"\u001b[39m\u001b[33mLOAD_IN_8BIT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[32m     28\u001b[39m                                       dtype=\u001b[38;5;28mglobals\u001b[39m().get(\u001b[33m\"\u001b[39m\u001b[33mDTYPE\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m     29\u001b[39m judge = Judge(JudgeConfig(provider=JUDGE_PROVIDER, model=JUDGE_MODEL,\n\u001b[32m     30\u001b[39m                           temperature=JUDGE_TEMPERATURE))\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m baseline = \u001b[43mcompute_baseline_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLAYER\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# CONTROL\u001b[39;00m\n\u001b[32m     34\u001b[39m ctrl_dir = os.path.join(root, \u001b[33m\"\u001b[39m\u001b[33mprefill_control\u001b[39m\u001b[33m\"\u001b[39m); os.makedirs(ctrl_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/ai-introspection/src/introspect_repro/concept_vectors.py:37\u001b[39m, in \u001b[36mcompute_baseline_mean\u001b[39m\u001b[34m(model, tok, layer_idx)\u001b[39m\n\u001b[32m     35\u001b[39m     text = _prompt_for_concept(w)\n\u001b[32m     36\u001b[39m     idx = _token_index_of_last_colon(tok, text)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     v = \u001b[43mget_residual_at_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtok\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     vecs.append(v)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.stack(vecs, dim=\u001b[32m0\u001b[39m).mean(dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/ai-introspection/src/introspect_repro/concept_vectors.py:28\u001b[39m, in \u001b[36mget_residual_at_token\u001b[39m\u001b[34m(model, tok, text, layer_idx, token_index)\u001b[39m\n\u001b[32m     26\u001b[39m ids = tok(text, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m).to(device)\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ResidualCapture(model, layer_idx, capture_output=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m cap:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     _ = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m hs = cap.buffer  \u001b[38;5;66;03m# [B, T, D]\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m hs[\u001b[32m0\u001b[39m, token_index, :].detach().cpu()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/jhvenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/jhvenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/jhvenv/lib/python3.12/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/jhvenv/lib/python3.12/site-packages/transformers/utils/generic.py:918\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    920\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/jhvenv/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:473\u001b[39m, in \u001b[36mLlamaForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    471\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n\u001b[32m    472\u001b[39m slice_indices = \u001b[38;5;28mslice\u001b[39m(-logits_to_keep, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(logits_to_keep, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m logits_to_keep\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlm_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m loss = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/jhvenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/jhvenv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/jhvenv/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_forward\u001b[39m(module, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     args, kwargs = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_hf_hook\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module._hf_hook.no_grad:\n\u001b[32m    172\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/jhvenv/lib/python3.12/site-packages/accelerate/hooks.py:360\u001b[39m, in \u001b[36mAlignDevicesHook.pre_forward\u001b[39m\u001b[34m(self, module, *args, **kwargs)\u001b[39m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    353\u001b[39m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    354\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    355\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m value.data_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map\n\u001b[32m    356\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.execution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map[value.data_ptr()]\n\u001b[32m    357\u001b[39m         ):\n\u001b[32m    358\u001b[39m             \u001b[38;5;28mself\u001b[39m.tied_pointers_to_remove.add((value.data_ptr(), \u001b[38;5;28mself\u001b[39m.execution_device))\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m.execution_device), send_to_device(\n\u001b[32m    370\u001b[39m     kwargs, \u001b[38;5;28mself\u001b[39m.execution_device, skip_keys=\u001b[38;5;28mself\u001b[39m.skip_keys\n\u001b[32m    371\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/jhvenv/lib/python3.12/site-packages/accelerate/utils/modeling.py:343\u001b[39m, in \u001b[36mset_module_tensor_to_device\u001b[39m\u001b[34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map, non_blocking, clear_cache)\u001b[39m\n\u001b[32m    341\u001b[39m             module._parameters[tensor_name] = param_cls(new_value, requires_grad=old_value.requires_grad)\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, torch.Tensor):\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m     new_value = \u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    345\u001b[39m     new_value = torch.tensor(value, device=device)\n",
      "\u001b[31mOutOfMemoryError\u001b[39m: CUDA out of memory. Tried to allocate 1.96 GiB. GPU 0 has a total capacity of 31.35 GiB of which 1.86 GiB is free. Process 3433 has 602.00 MiB memory in use. Including non-PyTorch memory, this process has 28.68 GiB memory in use. Of the allocated memory 28.08 GiB is allocated by PyTorch, and 19.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "# (Optional) Generate Control + Random‑Other runs here (Matched: run the standard CLI)\n",
    "TS = None  #@param {type:\"string\"}\n",
    "N_TRIALS = 30  #@param {type:\"integer\"}\n",
    "LAYER =  12    #@param {type:\"integer\"}\n",
    "STRENGTHS = [0,1,2,4,8]  # include 0 for control  #@param\n",
    "\n",
    "import time, os, random, json, sys\n",
    "from src.introspect_repro.models import load_model_and_tokenizer\n",
    "from src.introspect_repro.word_lists import CONCEPT_WORDS, SENTENCES\n",
    "from src.introspect_repro.prompts import PREFILL_PROMPT\n",
    "from src.introspect_repro.concept_vectors import compute_baseline_mean, compute_concept_vector\n",
    "from src.introspect_repro.generation import generate_with_optional_injection\n",
    "from src.introspect_repro.judges import Judge, JudgeConfig\n",
    "\n",
    "if TS is None:\n",
    "    TS = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "root = os.path.join(\"runs\", TS)\n",
    "os.makedirs(root, exist_ok=True)\n",
    "\n",
    "HF_MODEL = globals().get(\"HF_MODEL\", \"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "JUDGE_PROVIDER = globals().get(\"JUDGE_PROVIDER\", \"openai\")\n",
    "JUDGE_MODEL = globals().get(\"JUDGE_MODEL\", \"gpt-4o-mini\")\n",
    "JUDGE_TEMPERATURE = globals().get(\"JUDGE_TEMPERATURE\", 0.0)\n",
    "\n",
    "model, tok = load_model_and_tokenizer(HF_MODEL, device=\"cuda\",\n",
    "                                      load_in_4bit=globals().get(\"LOAD_IN_4BIT\", False),\n",
    "                                      load_in_8bit=globals().get(\"LOAD_IN_8BIT\", False),\n",
    "                                      dtype=globals().get(\"DTYPE\", None))\n",
    "judge = Judge(JudgeConfig(provider=JUDGE_PROVIDER, model=JUDGE_MODEL,\n",
    "                          temperature=JUDGE_TEMPERATURE))\n",
    "baseline = compute_baseline_mean(model, tok, LAYER)\n",
    "\n",
    "# CONTROL\n",
    "ctrl_dir = os.path.join(root, \"prefill_control\"); os.makedirs(ctrl_dir, exist_ok=True)\n",
    "trials = []\n",
    "for i in range(N_TRIALS):\n",
    "    w = random.choice(CONCEPT_WORDS); sent = random.choice(SENTENCES)\n",
    "    prompt = PREFILL_PROMPT.format(sentence=sent, word=w.lower())\n",
    "    resp = generate_with_optional_injection(model, tok, prompt, None, None, 0.0,\n",
    "                                            token_range=None, max_new_tokens=64, temperature=0.0)\n",
    "    intended = judge.grade_intent(resp, w)\n",
    "    trials.append(dict(word=w, sentence=sent, response=resp, intended=intended, condition=\"control\"))\n",
    "with open(os.path.join(ctrl_dir, f\"layer{LAYER}_strength0.json\"), \"w\") as f:\n",
    "    json.dump(dict(layer=LAYER, strength=0, trials=trials), f, indent=2)\n",
    "print(\"Wrote:\", ctrl_dir)\n",
    "\n",
    "# RANDOM‑OTHER\n",
    "rand_dir = os.path.join(root, \"prefill_random\"); os.makedirs(rand_dir, exist_ok=True)\n",
    "for s in [x for x in STRENGTHS if x>0]:\n",
    "    trials = []\n",
    "    for i in range(N_TRIALS):\n",
    "        w = random.choice(CONCEPT_WORDS); sent = random.choice(SENTENCES)\n",
    "        prompt = PREFILL_PROMPT.format(sentence=sent, word=w.lower())\n",
    "        other = random.choice([x for x in CONCEPT_WORDS if x != w])\n",
    "        vec = compute_concept_vector(model, tok, other, LAYER, cached_baseline=baseline)\n",
    "        resp = generate_with_optional_injection(model, tok, prompt, LAYER, vec, s,\n",
    "                                                token_range=None, max_new_tokens=64, temperature=0.0)\n",
    "        intended = judge.grade_intent(resp, w)\n",
    "        trials.append(dict(word=w, sentence=sent, injected_other=other, response=resp, intended=intended, condition=\"random_other\"))\n",
    "    with open(os.path.join(rand_dir, f\"layer{LAYER}_strength{s}.json\"), \"w\") as f:\n",
    "        json.dump(dict(layer=LAYER, strength=s, trials=trials), f, indent=2)\n",
    "print(\"Wrote:\", rand_dir)\n",
    "\n",
    "print(\"For MATCHED condition, run the standard CLI with --outdir\", os.path.join(root, \"prefill_intention\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9ac3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Prefill panel (control vs matched vs random-other)\n",
    "TS = None  #@param {type:\"string\"}\n",
    "STRENGTHS = [1,2,4,8]  #@param\n",
    "N_COLS = 3             # control, matched, random-other  #@param {type:\"integer\"}\n",
    "\n",
    "import glob, os, sys, subprocess\n",
    "if TS:\n",
    "    root = os.path.join(\"runs\", TS)\n",
    "else:\n",
    "    # guess latest that has all three\n",
    "    candidates = sorted(glob.glob(os.path.join(\"runs\", \"*\")), key=os.path.getmtime)\n",
    "    root = None\n",
    "    for r in reversed(candidates):\n",
    "        if all(os.path.isdir(os.path.join(r, d)) for d in [\"prefill_control\",\"prefill_intention\",\"prefill_random\"]):\n",
    "            root = r; break\n",
    "\n",
    "if not root:\n",
    "    raise SystemExit(\"Could not find a runs/<TS>/ with prefill_control, prefill_intention, and prefill_random.\")\n",
    "\n",
    "dirs = {\n",
    "    \"Control (no injection)\": os.path.join(root, \"prefill_control\"),\n",
    "    \"Matched (prefill word)\": os.path.join(root, \"prefill_intention\"),\n",
    "    \"Random other word\": os.path.join(root, \"prefill_random\"),\n",
    "}\n",
    "\n",
    "per_tile = []\n",
    "for s in STRENGTHS:\n",
    "    for name, d in dirs.items():\n",
    "        out_png = os.path.join(d, f\"prefill_layerwise_strength{s}.png\")\n",
    "        cmd = [sys.executable, \"-m\", \"introspect_repro.plotting.plot_prefill_intention\",\n",
    "               \"--run-dir\", d, \"--strength\", str(s), \"--save\", out_png]\n",
    "        print(\">>>\", \" \".join(cmd))\n",
    "        subprocess.run(cmd, check=True)\n",
    "        per_tile.append(out_png)\n",
    "\n",
    "panel_path = os.path.join(root, f\"panel_prefill_{'_'.join(map(str,STRENGTHS))}.png\")\n",
    "panel_path = tile_images(per_tile, panel_path, n_cols=N_COLS)\n",
    "panel_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0d58c",
   "metadata": {},
   "source": [
    "## 5) Intentional Control — small multiples (token‑level traces)\n",
    "\n",
    "Find the layer with the largest average **Think − Don’t** gap, render **N** per‑trial token traces as single‑plot images, and tile them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a72686c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Intentional‑Control small‑multiples panel\n",
    "RUN_DIR = latest_run_dir(\"intentional_control\")  #@param {type:\"string\"}\n",
    "N_EXAMPLES = 12                                   #@param {type:\"integer\"}\n",
    "N_COLS = 4                                        #@param {type:\"integer\"}\n",
    "\n",
    "import json, os, glob, numpy as np, matplotlib.pyplot as plt\n",
    "from introspect_repro.plotting.utils import _extract_layer_strength\n",
    "\n",
    "files = sorted(glob.glob(os.path.join(RUN_DIR, \"layer*.json\")))\n",
    "if not files: raise SystemExit(\"No intentional_control layer*.json files found in \" + str(RUN_DIR))\n",
    "\n",
    "# choose best layer by mean gap\n",
    "best = None\n",
    "for f in files:\n",
    "    with open(f, \"r\") as fh: j = json.load(fh)\n",
    "    sims_t = []; sims_d = []\n",
    "    for t in j[\"trials\"]:\n",
    "        sims_t.extend(t[\"sims_think\"]); sims_d.extend(t[\"sims_dont\"])\n",
    "    if sims_t and sims_d:\n",
    "        gap = float(np.mean(sims_t) - np.mean(sims_d))\n",
    "        layer, _ = _extract_layer_strength(os.path.basename(f))\n",
    "        if (best is None) or (gap > best[0]):\n",
    "            best = (gap, layer, j, f)\n",
    "gap, layer, j, f = best\n",
    "print(\"Best layer:\", layer, \"gap:\", gap)\n",
    "\n",
    "tmp_imgs = []\n",
    "for i, t in enumerate(j[\"trials\"][:N_EXAMPLES]):\n",
    "    plt.figure()\n",
    "    plt.plot(t[\"sims_think\"], label=\"Think\")\n",
    "    plt.plot(t[\"sims_dont\"], label=\"Don't think\")\n",
    "    plt.xlabel(\"Token index\")\n",
    "    plt.ylabel(\"Cosine similarity\")\n",
    "    plt.title(f\"Trial {i+1} – layer {layer}\")\n",
    "    plt.legend()\n",
    "    out_png = os.path.join(RUN_DIR, f\"intent_small_{i+1:02d}.png\")\n",
    "    plt.savefig(out_png, bbox_inches=\"tight\", dpi=160)\n",
    "    tmp_imgs.append(out_png)\n",
    "    plt.close()\n",
    "\n",
    "panel_path = os.path.join(RUN_DIR, f\"panel_intent_smallmultiples_layer{layer}.png\")\n",
    "panel_path = tile_images(tmp_imgs, panel_path, n_cols=N_COLS)\n",
    "panel_path"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
